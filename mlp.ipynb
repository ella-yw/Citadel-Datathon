{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNF+rsu7jveO9/i7Z3NGTqX"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_ItmmKsPTK4Q","executionInfo":{"status":"ok","timestamp":1690745784226,"user_tz":240,"elapsed":17171,"user":{"displayName":"Andy Jiang","userId":"09434980078266214903"}},"outputId":"a640a14e-f014-4b81-94a8-46601d6a74e8"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","source":["!pip install torch-scatter -f https://pytorch-geometric.com/whl/torch-1.13.1+cu116.html\n","!pip install torch-sparse -f https://pytorch-geometric.com/whl/torch-1.13.1+cu116.html\n","!pip install torch-geometric\n","!pip install ogb"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wWZ8YVd3TOoi","executionInfo":{"status":"ok","timestamp":1690745828203,"user_tz":240,"elapsed":43981,"user":{"displayName":"Andy Jiang","userId":"09434980078266214903"}},"outputId":"88af01f1-6580-474c-ab00-e167d3424f91"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in links: https://pytorch-geometric.com/whl/torch-1.13.1+cu116.html\n","Collecting torch-scatter\n","  Downloading https://data.pyg.org/whl/torch-1.13.0%2Bcu116/torch_scatter-2.1.1%2Bpt113cu116-cp310-cp310-linux_x86_64.whl (9.4 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.4/9.4 MB\u001b[0m \u001b[31m29.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: torch-scatter\n","Successfully installed torch-scatter-2.1.1+pt113cu116\n","Looking in links: https://pytorch-geometric.com/whl/torch-1.13.1+cu116.html\n","Collecting torch-sparse\n","  Downloading https://data.pyg.org/whl/torch-1.13.0%2Bcu116/torch_sparse-0.6.17%2Bpt113cu116-cp310-cp310-linux_x86_64.whl (4.5 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m19.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from torch-sparse) (1.10.1)\n","Requirement already satisfied: numpy<1.27.0,>=1.19.5 in /usr/local/lib/python3.10/dist-packages (from scipy->torch-sparse) (1.22.4)\n","Installing collected packages: torch-sparse\n","Successfully installed torch-sparse-0.6.17+pt113cu116\n","Collecting torch-geometric\n","  Downloading torch_geometric-2.3.1.tar.gz (661 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m661.6/661.6 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (4.65.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (1.22.4)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (1.10.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (3.1.2)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (2.27.1)\n","Requirement already satisfied: pyparsing in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (3.1.0)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (1.2.2)\n","Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (5.9.5)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch-geometric) (2.1.3)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (1.26.16)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (2023.7.22)\n","Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (2.0.12)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (3.4)\n","Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch-geometric) (1.3.1)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch-geometric) (3.2.0)\n","Building wheels for collected packages: torch-geometric\n","  Building wheel for torch-geometric (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for torch-geometric: filename=torch_geometric-2.3.1-py3-none-any.whl size=910460 sha256=533a599648681584eb221eb3be5857f024416da1d3cdfee5b9eed80302939625\n","  Stored in directory: /root/.cache/pip/wheels/ac/dc/30/e2874821ff308ee67dcd7a66dbde912411e19e35a1addda028\n","Successfully built torch-geometric\n","Installing collected packages: torch-geometric\n","Successfully installed torch-geometric-2.3.1\n","Collecting ogb\n","  Downloading ogb-1.3.6-py3-none-any.whl (78 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.8/78.8 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from ogb) (2.0.1+cu118)\n","Requirement already satisfied: numpy>=1.16.0 in /usr/local/lib/python3.10/dist-packages (from ogb) (1.22.4)\n","Requirement already satisfied: tqdm>=4.29.0 in /usr/local/lib/python3.10/dist-packages (from ogb) (4.65.0)\n","Requirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.10/dist-packages (from ogb) (1.2.2)\n","Requirement already satisfied: pandas>=0.24.0 in /usr/local/lib/python3.10/dist-packages (from ogb) (1.5.3)\n","Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from ogb) (1.16.0)\n","Requirement already satisfied: urllib3>=1.24.0 in /usr/local/lib/python3.10/dist-packages (from ogb) (1.26.16)\n","Collecting outdated>=0.2.0 (from ogb)\n","  Downloading outdated-0.2.2-py2.py3-none-any.whl (7.5 kB)\n","Requirement already satisfied: setuptools>=44 in /usr/local/lib/python3.10/dist-packages (from outdated>=0.2.0->ogb) (67.7.2)\n","Collecting littleutils (from outdated>=0.2.0->ogb)\n","  Downloading littleutils-0.2.2.tar.gz (6.6 kB)\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from outdated>=0.2.0->ogb) (2.27.1)\n","Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24.0->ogb) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24.0->ogb) (2022.7.1)\n","Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.20.0->ogb) (1.10.1)\n","Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.20.0->ogb) (1.3.1)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.20.0->ogb) (3.2.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->ogb) (3.12.2)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->ogb) (4.7.1)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->ogb) (1.11.1)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->ogb) (3.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->ogb) (3.1.2)\n","Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->ogb) (2.0.0)\n","Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.6.0->ogb) (3.25.2)\n","Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.6.0->ogb) (16.0.6)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.6.0->ogb) (2.1.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->outdated>=0.2.0->ogb) (2023.7.22)\n","Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->outdated>=0.2.0->ogb) (2.0.12)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->outdated>=0.2.0->ogb) (3.4)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.6.0->ogb) (1.3.0)\n","Building wheels for collected packages: littleutils\n","  Building wheel for littleutils (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for littleutils: filename=littleutils-0.2.2-py3-none-any.whl size=7028 sha256=abaeb9630256c0fab5be519b16bc222f887150fa9fd94408521b028035e0bb2b\n","  Stored in directory: /root/.cache/pip/wheels/3d/fe/b0/27a9892da57472e538c7452a721a9cf463cc03cf7379889266\n","Successfully built littleutils\n","Installing collected packages: littleutils, outdated, ogb\n","Successfully installed littleutils-0.2.2 ogb-1.3.6 outdated-0.2.2\n"]}]},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","\n","import torch_geometric\n","from torch_geometric.data import Data\n","from torch_geometric.loader import DataLoader\n","from torch.utils.data import Dataset\n","import torch.nn.functional as F\n","\n","from tqdm.notebook import tqdm\n","\n","import numpy as np\n","import pandas as pd\n","\n","import os\n","\n","import math"],"metadata":{"id":"hpk-1jb-TPE1","executionInfo":{"status":"ok","timestamp":1690746973145,"user_tz":240,"elapsed":1,"user":{"displayName":"Andy Jiang","userId":"09434980078266214903"}}},"execution_count":33,"outputs":[]},{"cell_type":"code","source":["class GraphDataset(Dataset):\n","  def __init__(self, root, transform=None):\n","\n","    self.data = []\n","    for graph_folder in tqdm(os.listdir(root)):\n","      graph_path = os.path.join(root, graph_folder)\n","      self.data.append(convert_to_Data(graph_path))\n","\n","    self.create_idx_split()\n","\n","    self.task_type = \"regression\"\n","\n","    self.eval_metric = \"rmse\"\n","\n","\n","  def __len__(self):\n","    return len(self.data)\n","\n","  def __getitem__(self, idx):\n","    if torch.is_tensor(idx):\n","      # If the input 'idx' is a tensor, return a list of data items corresponding to the indices\n","      return [self.data[i] for i in idx]\n","    else:\n","      return self.data[idx]\n","\n","  def create_idx_split(self):\n","    split = {}\n","\n","    avail = list(range(len(self.data)))\n","\n","    train_prop = 0.7\n","    val_prop = 0.15\n","    test_prop = 0.15\n","\n","    num_train = int(train_prop * len(self.data))\n","    num_val = int(val_prop * len(self.data))\n","    num_test = len(self.data) - num_train - num_val\n","\n","    train_split = random.sample(avail, num_train)\n","    avail = list(set(avail) - set(train_split))\n","\n","    val_split = random.sample(avail, num_val)\n","    avail = list(set(avail) - set(val_split))\n","\n","    test_split = random.sample(avail, num_test)\n","    avail = list(set(avail) - set(test_split))\n","\n","    split['train'] = torch.tensor(train_split)\n","    split['valid'] = torch.tensor(val_split)\n","    split['test'] = torch.tensor(test_split)\n","\n","    self.split = split\n","\n","  def get_idx_split(self):\n","    return self.split\n"],"metadata":{"id":"fx0jG0gwTQTb","executionInfo":{"status":"ok","timestamp":1690747616788,"user_tz":240,"elapsed":150,"user":{"displayName":"Andy Jiang","userId":"09434980078266214903"}}},"execution_count":65,"outputs":[]},{"cell_type":"code","source":["# Load the dataset\n","dataset = torch.load(\"/content/drive/MyDrive/Summer_Invitational_2023_Datathon_Datasets/Test-Data-Processed/NK.pt\")"],"metadata":{"id":"_xHBC2JuTS3H","executionInfo":{"status":"ok","timestamp":1690747633896,"user_tz":240,"elapsed":155,"user":{"displayName":"Andy Jiang","userId":"09434980078266214903"}}},"execution_count":68,"outputs":[]},{"cell_type":"code","source":["x = []\n","for data in dataset:\n","  e = data.edge_attr\n","  asum = 0\n","  ac = 0\n","  bsum = 0\n","  bc = 0\n","\n","  for row in e:\n","    if not math.isnan(row[0]):\n","      asum += row[0]\n","      ac += 1\n","    if not math.isnan(row[1]):\n","      bsum += row[1]\n","      bc += 1\n","  x.append([asum / ac, bsum / bc])\n","\n","x = torch.tensor(x)\n","x.resize_(x.shape[0], 2)\n","print(x.shape)\n","\n","y = []\n","for data in dataset:\n","  y.append(data.y)\n","y = torch.tensor(y)\n","y.resize_(y.shape[0], 1)\n","print(y.shape)\n"],"metadata":{"id":"MbyDkpLdURTQ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1690747637046,"user_tz":240,"elapsed":2086,"user":{"displayName":"Andy Jiang","userId":"09434980078266214903"}},"outputId":"c2e7cf96-130a-4de6-8a2c-296fea87fe48"},"execution_count":69,"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([365, 2])\n","torch.Size([365, 1])\n"]}]},{"cell_type":"code","source":["from torch.utils.data import TensorDataset, DataLoader\n","\n","ds = TensorDataset(x, y)\n","\n","train_loader = DataLoader(ds, batch_size=2, shuffle=True)\n","test_loader = DataLoader(ds, batch_size=2, shuffle=True)"],"metadata":{"id":"mkpt9hXaZijx","executionInfo":{"status":"ok","timestamp":1690747637046,"user_tz":240,"elapsed":3,"user":{"displayName":"Andy Jiang","userId":"09434980078266214903"}}},"execution_count":70,"outputs":[]},{"cell_type":"code","source":["num_epochs = 25"],"metadata":{"id":"KguD_1iIUM3a","executionInfo":{"status":"ok","timestamp":1690747637047,"user_tz":240,"elapsed":3,"user":{"displayName":"Andy Jiang","userId":"09434980078266214903"}}},"execution_count":71,"outputs":[]},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","\n","class MLPRegression(nn.Module):\n","    def __init__(self, input_size, hidden_size, output_size):\n","        super(MLPRegression, self).__init__()\n","        self.fc1 = nn.Linear(input_size, hidden_size)\n","        self.fc2 = nn.Linear(hidden_size, output_size)\n","\n","    def forward(self, x):\n","        x = torch.relu(self.fc1(x))\n","        x = self.fc2(x)\n","        return x\n","\n","# Example usage:\n","input_size = 2  # Replace with the input size of your data\n","hidden_size = 64\n","output_size = 1  # Regression output should have a single neuron\n","\n","# Create an instance of the MLP regression model\n","model = MLPRegression(input_size, hidden_size, output_size)\n","\n","# Define loss function and optimizer for regression (Mean Squared Error loss)\n","criterion = nn.MSELoss()\n","optimizer = optim.SGD(model.parameters(), lr=0.01)\n","\n","# Training loop example (assuming you have your data loaded as `train_loader`)\n","for epoch in range(num_epochs):\n","    running_loss = 0.0\n","    for inputs, targets in train_loader:\n","        optimizer.zero_grad()\n","        outputs = model(inputs)\n","        loss = criterion(outputs, targets)\n","        loss.backward()\n","        optimizer.step()\n","        running_loss += loss.item()\n","\n","    print(f\"Epoch {epoch+1}, Loss: {running_loss/len(train_loader)}\")\n","\n","# After training, you can use the model for predictions on new data\n","# For example, if you have test data loaded as `test_loader`:\n","model.eval()\n","with torch.no_grad():\n","    total_loss = 0.0\n","    num_samples = 0\n","    for inputs, targets in test_loader:\n","        outputs = model(inputs)\n","        loss = criterion(outputs, targets)\n","        total_loss += loss.item()\n","        num_samples += len(targets)\n","\n","    avg_loss = total_loss / num_samples\n","    print(f\"Average loss on test set: {avg_loss:.2f}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"t0e6P7CKTs_2","executionInfo":{"status":"ok","timestamp":1690747640571,"user_tz":240,"elapsed":3316,"user":{"displayName":"Andy Jiang","userId":"09434980078266214903"}},"outputId":"1d777c5e-560b-4a8b-c5db-f88b9b7a6d7c"},"execution_count":72,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1, Loss: 1.6981837924133883e+18\n","Epoch 2, Loss: 11308080626794.316\n","Epoch 3, Loss: 6952363111.136612\n","Epoch 4, Loss: 4274693.175866633\n","Epoch 5, Loss: 2638.517643850032\n","Epoch 6, Loss: 8.625202200512906\n","Epoch 7, Loss: 6.873945707404386\n","Epoch 8, Loss: 6.947745039122678\n","Epoch 9, Loss: 6.887807130923971\n","Epoch 10, Loss: 7.014142767241214\n","Epoch 11, Loss: 6.906698195713183\n","Epoch 12, Loss: 6.921781750970973\n","Epoch 13, Loss: 6.903396966434568\n","Epoch 14, Loss: 6.899027215978487\n","Epoch 15, Loss: 6.8999135268093825\n","Epoch 16, Loss: 6.913205554250811\n","Epoch 17, Loss: 6.885802300738507\n","Epoch 18, Loss: 6.890907915298893\n","Epoch 19, Loss: 6.917697260509496\n","Epoch 20, Loss: 6.878475078253235\n","Epoch 21, Loss: 6.8942594957522685\n","Epoch 22, Loss: 6.975306137307175\n","Epoch 23, Loss: 6.887254616601871\n","Epoch 24, Loss: 6.899647037867619\n","Epoch 25, Loss: 6.9044062387239515\n","Average loss on test set: 3.43\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"syxhykD1Tt-1"},"execution_count":null,"outputs":[]}]}